{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python-headless\n",
    "!pip install tensorflow==1.5\n",
    "!pip install keras\n",
    "!pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl\n",
    "#!pip install sk-video\n",
    "#!pip install pytube\n",
    "#!pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "#import skvideo.io\n",
    "import imageio\n",
    "#import pytube\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "#import humanize\n",
    "#from tqdm import tqdm\n",
    "\n",
    "from skimage.measure import compare_mse, compare_ssim\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import hamming\n",
    "from imageai.Detection import ObjectDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/idies/workspace/Storage/Cong/persistent/video/data'\n",
    "data_path = '/home/idies/workspace/Storage/Cong/persistent/video/data'\n",
    "result_path = '/home/idies/workspace/Storage/Cong/persistent/video/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_crop(h1, h2, l1, l2, original):\n",
    "    return original[h1:h2, l1:l2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mask(img, coordinates):\n",
    "    mask = np.zeros(img.shape, dtype = 'uint8')\n",
    "    \n",
    "    for coord in coordinates:\n",
    "        cv2.rectangle(mask, coord[0], coord[1], (255, 255, 255), -1);\n",
    "        \n",
    "    maskedImg = cv2.bitwise_and(img, mask)\n",
    "    return maskedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_object(img, model='resnet50_coco_best_v2.0.1.h5', minimum_prob=80):\n",
    "    detector = ObjectDetection()\n",
    "    detector.setModelTypeAsRetinaNet()\n",
    "    detector.setModelPath(os.path.join('/home/idies/workspace/Storage/Cong/persistent/video', model))\n",
    "    detector.loadModel()\n",
    "    detections = detector.detectObjectsFromImage(input_image=img, input_type='array', minimum_percentage_probability=minimum_prob)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FPS(video_loc):\n",
    "    video = cv2.VideoCapture(video_loc)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    h, w = img.shape\n",
    "    hist = [0.0] * 256\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            hist[img[i, j]] += 1\n",
    "    return np.array(hist) / (h * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_exposure(img):\n",
    "    '''\n",
    "    Normalize the exposure of an image.\n",
    "    '''\n",
    "    img = img.astype(int)\n",
    "    hist = get_histogram(img)\n",
    "    # get the sum of vals accumulated by each position in hist\n",
    "    cdf = np.array([sum(hist[:i+1]) for i in range(len(hist))])\n",
    "    # determine the normalization values for each unit of the cdf\n",
    "    sk = np.uint8(255 * cdf)\n",
    "    # normalize each position in the output image\n",
    "    h, w = img.shape\n",
    "    normalized = np.zeros_like(img)\n",
    "    for i in range(0, h):\n",
    "        for j in range(0, w):\n",
    "            normalized[i, j] = sk[img[i, j]]\n",
    "    return normalized.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_emd(img1, img2):\n",
    "    img1 = normalize_exposure(img1)\n",
    "    img2 = normalize_exposure(img2)\n",
    "    return wasserstein_distance(get_histogram(img1), get_histogram(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_orb(img1, img2, threshold):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp_1, desc_1 = orb.detectAndCompute(img1, None)\n",
    "    kp_2, desc_2 = orb.detectAndCompute(img2, None)\n",
    "    if desc_1 is None or desc_2 is None:\n",
    "        return 0\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(desc_1, desc_2)\n",
    "    if len(matches) == 0:\n",
    "        return 0\n",
    "    similar = [i for i in matches if i.distance < threshold]\n",
    "    return len(similar) / len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhash(img, hashSize=8):\n",
    "    # resize the input image, adding a single column (row) so we can compute the gradient\n",
    "    resized_col = cv2.resize(img, (hashSize+1,hashSize))\n",
    "    resized_row = cv2.resize(img, (hashSize,hashSize+1))\n",
    " \n",
    "    # compute the (relative) gradient between adjacent pixels\n",
    "    diff_col = resized_col[:,1:] > resized_col[:,:-1]\n",
    "    diff_row = resized_row[1:,:] > resized_row[:-1,:]\n",
    "\n",
    "    # convert the difference image to a hash\n",
    "    return sum([2**i for (i, v) in enumerate(np.append(diff_col.flatten(), diff_row.flatten())) if v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dhash(img1, img2, hashSize=8):\n",
    "    h1 = [int(d) for d in str(int(dhash(img1)))]\n",
    "    h2 = [int(d) for d in str(int(dhash(img2)))]\n",
    "    \n",
    "    if len(h1) == len(h2):\n",
    "        dHash = hamming(h1, h2)\n",
    "    else:\n",
    "        dHash = 1\n",
    "    return dHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_phash(img1, img2):\n",
    "    phash = cv2.img_hash_PHash.create()\n",
    "    return phash.compare(phash.compute(img1), phash.compute(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcarcoords = np.load(os.path.join(data_path, 'carcoords', 'allcarcoords.npy')).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_image(image_df, method, ascending, idx, start, end, coords):\n",
    "    results_dict = {}\n",
    "            \n",
    "    for i in range(start, min(end, image_df.shape[0])):\n",
    "        \n",
    "        img = imread(image_df['img_path'][idx])\n",
    "        \n",
    "        #i = i - image_df['img_index'][0]\n",
    "        temp_img = imread(image_df['img_path'][i])\n",
    "        \n",
    "        if method == 'EMD' or method == 'ORB' or method == 'dHash':\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            temp_img = cv2.cvtColor(temp_img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        #img = image_crop(h1, h2, l1, l2, img)\n",
    "        img = add_mask(img, coords)\n",
    "        #temp_img = image_crop(h1, h2, l1, l2, temp_img)\n",
    "        temp_img = add_mask(temp_img, coords)\n",
    "        \n",
    "        detections = allcarcoords[idx][2]\n",
    "        #detections = detect_object(img)\n",
    "        carcoords = []\n",
    "        for detection in detections:\n",
    "            if detection.get('name') == 'car':\n",
    "                temp = detection.get('box_points')\n",
    "                carcoords.append(temp)\n",
    "        \n",
    "        tempdetections = allcarcoords[i][2]\n",
    "        #tempdetections = detect_object(temp_img)\n",
    "        for detection in tempdetections:\n",
    "            if detection.get('name') == 'car':\n",
    "                temp = detection.get('box_points')\n",
    "                carcoords.append(temp)\n",
    "        \n",
    "        for carcoord in carcoords:\n",
    "            cv2.rectangle(img,(carcoord[0],carcoord[1]),(carcoord[2],carcoord[3]),(0,0,0),-1);\n",
    "            cv2.rectangle(temp_img,(carcoord[0],carcoord[1]),(carcoord[2],carcoord[3]),(0,0,0),-1);\n",
    "        \n",
    "        if method == 'MSE':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_mse(img, temp_img)]\n",
    "        elif method == 'EMD':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_emd(img, temp_img)]\n",
    "        elif method == 'ORB':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_orb(img, temp_img, threshold)]\n",
    "        elif method == 'dHash':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_dhash(img, temp_img)]\n",
    "        elif method == 'pHash':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_phash(img, temp_img)]\n",
    "        else:\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_ssim(img, temp_img, multichannel=True)]\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    results_df.columns = ['img_path', 'img_index', method]\n",
    "    results_df = results_df.sort_values(by=method, ascending=ascending)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_index(df, n, method, ascending):\n",
    "    temp = df.copy()[:n]\n",
    "    if ascending:\n",
    "        temp['weight'] = (1/(temp[method]+1e-8)) / sum(1/(temp[method]+1e-8))\n",
    "    else:\n",
    "        temp['weight'] = temp[method] / sum(temp[method])\n",
    "    return sum(temp['img_index']*temp['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords):\n",
    "    results_dict = {}\n",
    "    start = initial_idx + np.round(fps*prior_time).astype(int)\n",
    "    \n",
    "    #img_idxs = np.arange(initial_idx, initial_idx+3).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+3, initial_idx+6).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+6, initial_idx+9).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+9, initial_idx+12).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+12, initial_idx+15).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+15, initial_idx+18).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+18, initial_idx+21).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+21, initial_idx+24).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+24, initial_idx+27).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+27, np.round(initial_idx+fps).astype(int)).tolist()\n",
    "    \n",
    "    #img_idxs = np.arange(initial_idx, initial_idx+5).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+5, initial_idx+10).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+10, initial_idx+15).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+15, initial_idx+20).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+20, initial_idx+25).tolist()\n",
    "    img_idxs = np.arange(initial_idx+25, np.round(initial_idx+fps).astype(int)).tolist()\n",
    "    \n",
    "    #img_idxs = np.arange(initial_idx, initial_idx+10).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+10, initial_idx+20).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+20, np.round(initial_idx+fps).astype(int)).tolist()\n",
    "    \n",
    "    #img_idxs = np.choice(np.arange(initial_idx, np.round(initial_idx+fps).astype(int)), 10).tolist()\n",
    "    \n",
    "    for idx in img_idxs:\n",
    "        #img = imread(df['img_path'][idx])\n",
    "        start_time = time.time()\n",
    "        similar_imgs = get_similar_image(df, method, ascending, idx, start, end, coords)\n",
    "        elapsedTime = time.time() - start_time\n",
    "        results_dict[idx] = [df['img_path'][idx], df['img_index'][idx], \n",
    "                             (np.mean(similar_imgs.img_index[similar_imgs[method]==(similar_imgs[method].iloc[0])])-df['img_index'][idx])/fps, \n",
    "                             (weighted_index(similar_imgs, topn, method, ascending)-df['img_index'][idx])/fps, \n",
    "                             elapsedTime, method]\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    results_df.columns = ['img_path', 'img_index', 'lap_time', 'weighted_lap_time', 'elapsedTime', 'method']\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "initial_idx = 21681\n",
    "end = 26146\n",
    "prior_time = 60\n",
    "\n",
    "fps = 29.93930396046777\n",
    "topn = 5\n",
    "\n",
    "method = 'pHash'\n",
    "ascending = True\n",
    "\n",
    "coords = [[(0, 600), (1920, 740)], [(300, 0), (1920, 740)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords)\n",
    "test['lap'] = 9\n",
    "test.to_csv(os.path.join(result_path, '091108', 'lap9_pHash_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24359\n",
      "26155\n",
      "28828\n"
     ]
    }
   ],
   "source": [
    "temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_1.csv'))\n",
    "temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_2.csv'))\n",
    "temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_3.csv'))\n",
    "temp4 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_4.csv'))\n",
    "temp5 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_5.csv'))\n",
    "temp6 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_6.csv'))\n",
    "# temp7 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_7.csv'))\n",
    "# temp8 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_8.csv'))\n",
    "# temp9 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_9.csv'))\n",
    "# temp10 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_10.csv'))\n",
    "temp = temp1.append(temp2)\n",
    "temp = temp.append(temp3)\n",
    "temp = temp.append(temp4)\n",
    "temp = temp.append(temp5)\n",
    "temp = temp.append(temp6)\n",
    "# temp = temp.append(temp7)\n",
    "# temp = temp.append(temp8)\n",
    "# temp = temp.append(temp9)\n",
    "# temp = temp.append(temp10)\n",
    "\n",
    "# initial_idx\n",
    "print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# start\n",
    "print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# end\n",
    "print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(os.path.join(result_path, '091108', 'lap9_pHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.54227315615418"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('./result/091108/lap9_pHash.csv')\n",
    "np.median(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2761\n",
    "# end = 7315\n",
    "\n",
    "# initial_idx = 5519\n",
    "# end = 10077\n",
    "\n",
    "# initial_idx = 8237\n",
    "# end = 12752\n",
    "\n",
    "# initial_idx = 10933\n",
    "# end = 15432\n",
    "\n",
    "# initial_idx = 13626\n",
    "# end = 18055\n",
    "\n",
    "# initial_idx = 16316\n",
    "# end = 20747\n",
    "\n",
    "# initial_idx = 18984\n",
    "# end = 23416\n",
    "\n",
    "# initial_idx = 21681\n",
    "# end = 26146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2763\n",
    "# end = 7325\n",
    "\n",
    "# initial_idx = 5519\n",
    "# end = 10077\n",
    "\n",
    "# initial_idx = 8244\n",
    "# end = 12789\n",
    "\n",
    "# initial_idx = 10932\n",
    "# end = 15434\n",
    "\n",
    "# initial_idx = 13619\n",
    "# end = 18073\n",
    "\n",
    "# initial_idx = 16313\n",
    "# end = 20790\n",
    "\n",
    "# initial_idx = 18982\n",
    "# end = 23434\n",
    "\n",
    "# initial_idx = 21677\n",
    "# end = 26178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "# initial_idx = 27877\n",
    "# end = 31802\n",
    "# prior_time = 60\n",
    "\n",
    "# fps = 29.93943500598125\n",
    "# topn = 5\n",
    "\n",
    "# method = 'ORB'\n",
    "# ascending = False\n",
    "\n",
    "# coords = [[(0, 640), (1920, 810)], [(320, 0), (1920, 810)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords)\n",
    "# test['lap'] = 11\n",
    "# test.to_csv(os.path.join(result_path, '153240', 'lap11_ORB.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27877\n",
      "29673\n",
      "31802\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_6.csv'))\n",
    "# temp7 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_7.csv'))\n",
    "# temp8 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_8.csv'))\n",
    "# temp9 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_9.csv'))\n",
    "# temp10 = pd.read_csv(os.path.join(result_path, '153240', 'lap10_ORB_10.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "# temp = temp.append(temp7)\n",
    "# temp = temp.append(temp8)\n",
    "# temp = temp.append(temp9)\n",
    "# temp = temp.append(temp10)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '153240', 'lap10_ORB.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.12692672973195"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/153240/lap10_ORB.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2784\n",
    "# end = 7323\n",
    "\n",
    "# initial_idx = 5524\n",
    "# end = 10893\n",
    "\n",
    "# initial_idx = 8236\n",
    "# end = 13824\n",
    "\n",
    "# initial_idx = 10935\n",
    "# end = 15795\n",
    "\n",
    "# initial_idx = 15395\n",
    "# end = 20829\n",
    "\n",
    "# initial_idx = 18063\n",
    "# end = 22975\n",
    "\n",
    "# initial_idx = 20749\n",
    "# end = 25217\n",
    "\n",
    "# initial_idx = 23390\n",
    "# end = 27826\n",
    "\n",
    "# initial_idx = 26043\n",
    "# end = 30431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "# initial_idx = 26985\n",
    "# end = 31456\n",
    "# prior_time = 60\n",
    "\n",
    "# fps = 29.93943500598125\n",
    "# topn = 5\n",
    "\n",
    "# method = 'MSE'\n",
    "# ascending = True\n",
    "\n",
    "# coords = [[(0, 640), (1920, 810)], [(320, 0), (1920, 810)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords)\n",
    "# test['lap'] = 11\n",
    "# test.to_csv(os.path.join(result_path, '153240', 'lap11_MSE_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5410\n",
      "7206\n",
      "9835\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '153240', 'lap11_MSE.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.81394837527037"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/153240/lap11_MSE.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2786\n",
    "# end = 7363\n",
    "\n",
    "# initial_idx = 5527\n",
    "# end = 9348\n",
    "\n",
    "# initial_idx = 8236\n",
    "# end = 12741\n",
    "\n",
    "# initial_idx = 10940\n",
    "# end = 15438\n",
    "\n",
    "# initial_idx = 13666\n",
    "# end = 18190\n",
    "\n",
    "# initial_idx = 16355\n",
    "# end = 20839\n",
    "\n",
    "# initial_idx = 19039\n",
    "# end = 23520\n",
    "\n",
    "# initial_idx = 21693\n",
    "# end = 26140\n",
    "\n",
    "# initial_idx = 24297\n",
    "# end = 28744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "# initial_idx = 29332\n",
    "# end = 31230\n",
    "# prior_time = 5\n",
    "\n",
    "# fps = 29.93943500598125\n",
    "# topn = 5\n",
    "\n",
    "# method = 'pHash'\n",
    "# ascending = True\n",
    "\n",
    "# coords = [[(0, 640), (1920, 810)], [(320, 0), (1920, 810)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords)\n",
    "# test['lap'] = 11\n",
    "# test.to_csv(os.path.join(result_path, '153240', 'lap11_pHash_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26862\n",
      "28658\n",
      "28856\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '153240', 'lap11_pHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.62242512682876"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/153240/lap11_pHash.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2780\n",
    "# end = 7348\n",
    "\n",
    "# initial_idx = 5521\n",
    "# end = 10760\n",
    "\n",
    "# initial_idx = 8230\n",
    "# end = 12989\n",
    "\n",
    "# initial_idx = 12658\n",
    "# end = 17665\n",
    "\n",
    "# initial_idx = 15865\n",
    "# end = 20419\n",
    "\n",
    "# initial_idx = 18479\n",
    "# end = 22918\n",
    "\n",
    "# initial_idx = 21305\n",
    "# end = 25793\n",
    "\n",
    "# initial_idx = 24040\n",
    "# end = 28484\n",
    "\n",
    "# initial_idx = 26709\n",
    "# end = 31230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "# initial_idx = 21526\n",
    "# end = 26018\n",
    "# prior_time = 60\n",
    "\n",
    "# fps = 29.93930396046777\n",
    "# topn = 5\n",
    "\n",
    "# method = 'pHash'\n",
    "# ascending = True\n",
    "\n",
    "# coords = [[(0, 600), (1920, 740)], [(300, 0), (1920, 740)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, coords)\n",
    "# test['lap'] = 9\n",
    "# test.to_csv(os.path.join(result_path, '091108', 'lap9_pHash_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21514\n",
      "23310\n",
      "25991\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '091108', 'lap9_pHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.56249926282501"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/091108/lap9_pHash.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2767\n",
    "# end = 7323\n",
    "\n",
    "# initial_idx = 5526\n",
    "# end = 10083\n",
    "\n",
    "# initial_idx = 8247\n",
    "# end = 12763\n",
    "\n",
    "# initial_idx = 10944\n",
    "# end = 15439\n",
    "\n",
    "# initial_idx = 13632\n",
    "# end = 18064\n",
    "\n",
    "# initial_idx = 16320\n",
    "# end = 20752\n",
    "\n",
    "# initial_idx = 18831\n",
    "# end = 23219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "# initial_idx = 27001\n",
    "# end = 33056\n",
    "\n",
    "# fps = 29.93943500598125\n",
    "# topn = 5\n",
    "\n",
    "# method = 'ORB'\n",
    "# ascending = False\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 810\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 11\n",
    "# test.to_csv(os.path.join(result_path, '153240', 'lap11_ORB_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29631\n",
      "30529\n",
      "33110\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_ORB_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '153240', 'lap11_ORB.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.22295865472896"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/153240/lap11_ORB.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2784\n",
    "# end = 7362\n",
    "\n",
    "# initial_idx = 5524\n",
    "# end = 10062\n",
    "\n",
    "# initial_idx = 8236\n",
    "# end = 12744\n",
    "\n",
    "# initial_idx = 10939\n",
    "# end = 15436\n",
    "\n",
    "# initial_idx = 13666\n",
    "# end = 18190\n",
    "\n",
    "# initial_idx = 18103\n",
    "# end = 22645\n",
    "\n",
    "# initial_idx = 20785\n",
    "# end = 25260\n",
    "\n",
    "# initial_idx = 23429\n",
    "# end = 27863\n",
    "\n",
    "# initial_idx = 26084\n",
    "# end = 30523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "# initial_idx = 27001\n",
    "# end = 31470\n",
    "\n",
    "# fps = 29.93943500598125\n",
    "# topn = 5\n",
    "\n",
    "# method = 'pHash'\n",
    "# ascending = True\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 810\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 11\n",
    "# test.to_csv(os.path.join(result_path, '153240', 'lap11_pHash_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29623\n",
      "31419\n",
      "34028\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_pHash_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '153240', 'lap11_pHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.16374683797424"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/153240/lap11_pHash.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2791\n",
    "# end = 7361\n",
    "\n",
    "# initial_idx = 5515\n",
    "# end = 10237\n",
    "\n",
    "# initial_idx = 8214\n",
    "# end = 12717\n",
    "\n",
    "# initial_idx = 10923\n",
    "# end = 15425\n",
    "\n",
    "# initial_idx = 13650\n",
    "# end = 18175\n",
    "\n",
    "# initial_idx = 16338\n",
    "# end = 20818\n",
    "\n",
    "# initial_idx = 19028\n",
    "# end = 23511\n",
    "\n",
    "# initial_idx = 21678\n",
    "# end = 26129\n",
    "\n",
    "# initial_idx = 24334\n",
    "# end = 28778\n",
    "\n",
    "# initial_idx = 27001\n",
    "# end = 31470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "# initial_idx = 21661\n",
    "# end = 26156\n",
    "\n",
    "# fps = 29.93930396046777\n",
    "# topn = 5\n",
    "\n",
    "# method = 'ORB'\n",
    "# ascending = False\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 760\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 9\n",
    "# test.to_csv(os.path.join(result_path, '091108', 'lap9_ORB_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21640\n",
      "23436\n",
      "26115\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_ORB_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '091108', 'lap9_ORB.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.48437824531652"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/091108/lap9_ORB.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2756\n",
    "# end = 7308\n",
    "\n",
    "# initial_idx = 5511\n",
    "# end = 10067\n",
    "\n",
    "# initial_idx = 8227\n",
    "# end = 12740\n",
    "\n",
    "# initial_idx = 10917\n",
    "# end = 15406\n",
    "\n",
    "# initial_idx = 13607\n",
    "# end = 18091\n",
    "\n",
    "# initial_idx = 16297\n",
    "# end = 20783\n",
    "\n",
    "# initial_idx = 18963\n",
    "# end = 23425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "# initial_idx = 21684\n",
    "# end = 26149\n",
    "\n",
    "# fps = 29.93930396046777\n",
    "# topn = 5\n",
    "\n",
    "# method = 'pHash'\n",
    "# ascending = True\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 760\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 9\n",
    "# test.to_csv(os.path.join(result_path, '091108', 'lap9_pHash_3.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24359\n",
      "26155\n",
      "28842\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap9_pHash_3.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '091108', 'lap9_pHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.77719289051473"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/091108/lap9_pHash.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2766\n",
    "# end = 7323\n",
    "\n",
    "# initial_idx = 5524\n",
    "# end = 10080\n",
    "\n",
    "# initial_idx = 8245\n",
    "# end = 12760\n",
    "\n",
    "# initial_idx = 10937\n",
    "# end = 15398\n",
    "\n",
    "# initial_idx = 13623\n",
    "# end = 18104\n",
    "\n",
    "# initial_idx = 16316\n",
    "# end = 20805\n",
    "\n",
    "# initial_idx = 18983\n",
    "# end = 23449\n",
    "\n",
    "# initial_idx = 21684\n",
    "# end = 26149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "# initial_idx = 21229\n",
    "# end = 26502\n",
    "\n",
    "# fps = 29.93930396046777\n",
    "# topn = 5\n",
    "\n",
    "# method = 'dHash'\n",
    "# ascending = True\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 760\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 9\n",
    "# test.to_csv(os.path.join(result_path, '091108', 'lap9_dHash_1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24062\n",
      "25858\n",
      "28276\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_3.csv'))\n",
    "# temp4 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_4.csv'))\n",
    "# temp5 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_5.csv'))\n",
    "# temp6 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_dHash_6.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "# temp = temp.append(temp4)\n",
    "# temp = temp.append(temp5)\n",
    "# temp = temp.append(temp6)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '091108', 'lap8_dHash.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.79568816498539"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/091108/lap8_dHash.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2710\n",
    "# end = 7118\n",
    "\n",
    "# initial_idx = 4946\n",
    "# end = 9848\n",
    "\n",
    "# initial_idx = 8902\n",
    "# end = 13998\n",
    "\n",
    "# initial_idx = 11070\n",
    "# end = 16267\n",
    "\n",
    "# initial_idx = 13773\n",
    "# end = 18853\n",
    "\n",
    "# initial_idx = 18401\n",
    "# end = 23864\n",
    "\n",
    "# initial_idx = 21229\n",
    "# end = 26502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
