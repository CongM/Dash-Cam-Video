{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python-headless\n",
    "!pip install sk-video\n",
    "!pip install pytube\n",
    "!pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import skvideo.io\n",
    "import imageio\n",
    "import pytube\n",
    "\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import humanize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.measure import compare_mse, compare_ssim\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/idies/workspace/Storage/Cong/persistent/video/data'\n",
    "data_path = '/home/idies/workspace/Storage/Cong/persistent/video/data'\n",
    "result_path = '/home/idies/workspace/Storage/Cong/persistent/video/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_crop(h1, h2, l1, l2, original):\n",
    "    return original[h1:h2, l1:l2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FPS(video_loc):\n",
    "    video = cv2.VideoCapture(video_loc)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(img):\n",
    "    h, w = img.shape\n",
    "    hist = [0.0] * 256\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            hist[img[i, j]] += 1\n",
    "    return np.array(hist) / (h * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_exposure(img):\n",
    "    '''\n",
    "    Normalize the exposure of an image.\n",
    "    '''\n",
    "    img = img.astype(int)\n",
    "    hist = get_histogram(img)\n",
    "    # get the sum of vals accumulated by each position in hist\n",
    "    cdf = np.array([sum(hist[:i+1]) for i in range(len(hist))])\n",
    "    # determine the normalization values for each unit of the cdf\n",
    "    sk = np.uint8(255 * cdf)\n",
    "    # normalize each position in the output image\n",
    "    h, w = img.shape\n",
    "    normalized = np.zeros_like(img)\n",
    "    for i in range(0, h):\n",
    "        for j in range(0, w):\n",
    "            normalized[i, j] = sk[img[i, j]]\n",
    "    return normalized.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_emd(img1, img2):\n",
    "    img1 = normalize_exposure(img1)\n",
    "    img2 = normalize_exposure(img2)\n",
    "    return wasserstein_distance(get_histogram(img1), get_histogram(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_orb(img1, img2, threshold):\n",
    "    orb = cv2.ORB_create()\n",
    "    kp_1, desc_1 = orb.detectAndCompute(img1, None)\n",
    "    kp_2, desc_2 = orb.detectAndCompute(img2, None)\n",
    "    if desc_1 is None or desc_2 is None:\n",
    "        return 0\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(desc_1, desc_2)\n",
    "    if len(matches) == 0:\n",
    "        return 0\n",
    "    similar = [i for i in matches if i.distance < threshold]\n",
    "    return len(similar) / len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dhash(img, hashSize=8):\n",
    "    # resize the input image, adding a single column (row) so we can compute the gradient\n",
    "    resized_col = cv2.resize(img, (hashSize+1,hashSize))\n",
    "    resized_row = cv2.resize(img, (hashSize,hashSize+1))\n",
    " \n",
    "    # compute the (relative) gradient between adjacent pixels\n",
    "    diff_col = resized_col[:,1:] > resized_col[:,:-1]\n",
    "    diff_row = resized_row[1:,:] > resized_row[:-1,:]\n",
    "\n",
    "    # convert the difference image to a hash\n",
    "    return sum([2**i for (i, v) in enumerate(np.append(diff_col.flatten(), diff_row.flatten())) if v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dhash(img1, img2, hashSize=8):\n",
    "    h1 = [int(d) for d in str(int(dhash(img1)))]\n",
    "    h2 = [int(d) for d in str(int(dhash(img2)))]\n",
    "    \n",
    "    if len(h1) == len(h2):\n",
    "        dHash = hamming(h1, h2)\n",
    "    else:\n",
    "        dHash = 1\n",
    "    return dHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_phash(img1, img2):\n",
    "    phash = cv2.img_hash_PHash.create()\n",
    "    return phash.compare(phash.compute(img1), phash.compute(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_image(img, image_df, method, ascending, start, end, h1, h2, l1, l2):\n",
    "    results_dict = {}\n",
    "    img = image_crop(h1, h2, l1, l2, img)\n",
    "    if method == 'EMD' or method == 'ORB' or method == 'dHash':\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    for i in range(start, min(end, image_df.shape[0])):\n",
    "        #i = i - image_df['img_index'][0]\n",
    "        temp_img = imread(image_df['img_path'][i])\n",
    "        temp_img = image_crop(h1, h2, l1, l2, temp_img)\n",
    "        if method == 'MSE':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_mse(img, temp_img)]\n",
    "        elif method == 'EMD':\n",
    "            temp_img = cv2.cvtColor(temp_img, cv2.COLOR_RGB2GRAY)\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_emd(img, temp_img)]\n",
    "        elif method == 'ORB':\n",
    "            temp_img = cv2.cvtColor(temp_img, cv2.COLOR_RGB2GRAY)\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_orb(img, temp_img, threshold)]\n",
    "        elif method == 'dHash':\n",
    "            temp_img = cv2.cvtColor(temp_img, cv2.COLOR_RGB2GRAY)\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_dhash(img, temp_img)]\n",
    "        elif method == 'pHash':\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_phash(img, temp_img)]\n",
    "        else:\n",
    "            results_dict[i] = [image_df['img_path'][i], image_df['img_index'][i], compare_ssim(img, temp_img, multichannel=True)]\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    results_df.columns = ['img_path', 'img_index', method]\n",
    "    results_df = results_df.sort_values(by=method, ascending=ascending)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_index(df, n, method, ascending):\n",
    "    temp = df.copy()[:n]\n",
    "    if ascending:\n",
    "        temp['weight'] = (1/temp[method]) / sum(1/temp[method])\n",
    "    else:\n",
    "        temp['weight'] = temp[method] / sum(temp[method])\n",
    "    return sum(temp['img_index']*temp['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_time = 60\n",
    "threshold = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2):\n",
    "    results_dict = {}\n",
    "    start = initial_idx + np.round(fps*prior_time).astype(int)\n",
    "    \n",
    "    img_idxs = np.arange(initial_idx, initial_idx+5).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+5, initial_idx+10).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+10, initial_idx+15).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+15, initial_idx+20).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+20, initial_idx+25).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+25, np.round(initial_idx+fps).astype(int)).tolist()\n",
    "    \n",
    "    #img_idxs = np.arange(initial_idx, initial_idx+10).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+10, initial_idx+20).tolist()\n",
    "    #img_idxs = np.arange(initial_idx+20, np.round(initial_idx+fps).astype(int)).tolist()\n",
    "    \n",
    "    #img_idxs = np.choice(np.arange(initial_idx, np.round(initial_idx+fps).astype(int)), 10).tolist()\n",
    "    \n",
    "    for idx in img_idxs:\n",
    "        img = imread(df['img_path'][idx])\n",
    "        start_time = time.time()\n",
    "        similar_imgs = get_similar_image(img, df, method, ascending, start, end, h1, h2, l1, l2)\n",
    "        elapsedTime = time.time() - start_time\n",
    "        results_dict[idx] = [df['img_path'][idx], df['img_index'][idx], (similar_imgs['img_index'].iloc[0]-df['img_index'][idx])/fps, (weighted_index(similar_imgs, topn, method, ascending)-df['img_index'][idx])/fps, elapsedTime, method]\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    results_df.columns = ['img_path', 'img_index', 'lap_time', 'weighted_lap_time', 'elapsedTime', 'method']\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'train153240_raw.csv'))\n",
    "\n",
    "initial_idx = 26982\n",
    "end = 31455\n",
    "\n",
    "fps = 29.93943500598125\n",
    "topn = 5\n",
    "\n",
    "method = 'MSE'\n",
    "ascending = True\n",
    "\n",
    "h1 = 400\n",
    "h2 = 810\n",
    "l1 = 250\n",
    "l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "test['lap'] = 11\n",
    "test.to_csv(os.path.join(result_path, '153240', 'lap11_MSE_6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26916\n",
      "28712\n",
      "31335\n"
     ]
    }
   ],
   "source": [
    "temp1 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_1.csv'))\n",
    "temp2 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_2.csv'))\n",
    "temp3 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_3.csv'))\n",
    "temp4 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_4.csv'))\n",
    "temp5 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_5.csv'))\n",
    "temp6 = pd.read_csv(os.path.join(result_path, '153240', 'lap11_MSE_6.csv'))\n",
    "temp = temp1.append(temp2)\n",
    "temp = temp.append(temp3)\n",
    "temp = temp.append(temp4)\n",
    "temp = temp.append(temp5)\n",
    "temp = temp.append(temp6)\n",
    "\n",
    "\n",
    "# initial_idx\n",
    "print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# start\n",
    "print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# end\n",
    "print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(os.path.join(result_path, '153240', 'lap11_MSE.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.6168838682474"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('./result/153240/lap11_MSE.csv')\n",
    "np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2778\n",
    "# end = 7353\n",
    "\n",
    "# initial_idx = 4650\n",
    "# end = 8303\n",
    "\n",
    "# initial_idx = 8220\n",
    "# end = 12915\n",
    "\n",
    "# initial_idx = 10926\n",
    "# end = 15425\n",
    "\n",
    "# initial_idx = 13651\n",
    "# end = 18176\n",
    "\n",
    "# initial_idx = 16332\n",
    "# end = 20817\n",
    "\n",
    "# initial_idx = 19010\n",
    "# end = 23489\n",
    "\n",
    "# initial_idx = 21669\n",
    "# end = 26120\n",
    "\n",
    "# initial_idx = 24293\n",
    "# end = 28741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(data_path, 'train091108_raw.csv'))\n",
    "\n",
    "# initial_idx = 21682\n",
    "# end = 26174\n",
    "\n",
    "# fps = 29.93930396046777\n",
    "# topn = 5\n",
    "\n",
    "# method = 'MSE'\n",
    "# ascending = True\n",
    "\n",
    "# h1 = 400\n",
    "# h2 = 760\n",
    "# l1 = 250\n",
    "# l2 = 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = lap_time2(initial_idx, end, fps, topn, df, method, ascending, h1, h2, l1, l2)\n",
    "# test['lap'] = 8\n",
    "# test.to_csv(os.path.join(result_path, '091108', 'lap8_MSE_3.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21682\n",
      "23478\n",
      "26174\n"
     ]
    }
   ],
   "source": [
    "# temp1 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_MSE_1.csv'))\n",
    "# temp2 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_MSE_2.csv'))\n",
    "# temp3 = pd.read_csv(os.path.join(result_path, '091108', 'lap8_MSE_3.csv'))\n",
    "# temp = temp1.append(temp2)\n",
    "# temp = temp.append(temp3)\n",
    "\n",
    "# # initial_idx\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx)\n",
    "\n",
    "# # start\n",
    "# print(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int))\n",
    "\n",
    "# # end\n",
    "# print(int(int(temp['lap_time'].iloc[0] * fps) + initial_idx + np.round(fps*prior_time).astype(int) + np.mean(temp['lap_time']) * fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.to_csv(os.path.join(result_path, '091108', 'lap8_MSE.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.55006670184385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp = pd.read_csv('./result/091108/lap9_MSE.csv')\n",
    "# np.mean(temp['lap_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_idx = 0\n",
    "# end = 3600\n",
    "\n",
    "# initial_idx = 2766\n",
    "# end = 7323\n",
    "\n",
    "# initial_idx = 5527\n",
    "# end = 10083\n",
    "\n",
    "# initial_idx = 8249\n",
    "# end = 12763\n",
    "\n",
    "# initial_idx = 10942\n",
    "# end = 15434\n",
    "\n",
    "# initial_idx = 13629\n",
    "# end = 18110\n",
    "\n",
    "# initial_idx = 16316\n",
    "# end = 20801\n",
    "\n",
    "# initial_idx = 18984\n",
    "# end = 23448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
